{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gslmFev7hWhu"
   },
   "source": [
    "<h1>Train data from Kaggle Twitter sentiment (Sentiment140 dataset with 1.6 million tweets)</h1>\n",
    "https://www.kaggle.com/kazanova/sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1W-cSRv_hnwU",
    "outputId": "42855fa5-a5f9-40f8-b000-1e1db81c6079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U8gm-NVficYU"
   },
   "outputs": [],
   "source": [
    "pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L67Kj3EFhWh2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "#for data cleansing\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import contractions\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4fRhYJHjmbE"
   },
   "source": [
    "# Clean Data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I7TuItbOgtuQ"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/training.1600000.processed.noemoticonf.csv',encoding ='latin',engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zNUlOKu6hWiD"
   },
   "outputs": [],
   "source": [
    "df = df[[0,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dvXDxHnchWiH",
    "outputId": "949cc438-e36c-4836-c5ea-5f7dc0ce8826"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZahXaxSnhWiM"
   },
   "outputs": [],
   "source": [
    "df.columns=['sentiment','tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xea4gmrphWiQ",
    "outputId": "75a84462-4927-44f7-9e58-acacf8f19380"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment     0\n",
       "tweet_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBOiZsyIhWiU"
   },
   "outputs": [],
   "source": [
    "# 0 is negative, 1 is positive >> replace 4 with 1\n",
    "df['sentiment'] = df['sentiment'].apply(lambda x: 1 if x==4 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gopkS6SYhWiX",
    "outputId": "ccf9f5a5-ee82-4aa1-f45c-4db04facd155"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    800000\n",
       "0    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Blgz6Y-ihWic"
   },
   "outputs": [],
   "source": [
    "#dataset are with target 0 on the first 80000 rows and target 1 on the last 80000 rows\n",
    "df['sentiment'].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dSvtUVYkhWif"
   },
   "outputs": [],
   "source": [
    "#shuffle the dataframe\n",
    "newdf = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yi4OuL9chWij",
    "outputId": "0da6eea1-41d5-416c-c28d-81802bd4c554"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@agardina Yay! Yes, drive right to us, You can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@yeevs just come join me. the one in Gardens. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Just landed in Hotlanta! I have like 15 minute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Yay! Live improve musical theater is ridiculou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Weirdest night I have had in a long time! Haha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                         tweet_text\n",
       "0          1  @agardina Yay! Yes, drive right to us, You can...\n",
       "1          1  @yeevs just come join me. the one in Gardens. ...\n",
       "2          1  Just landed in Hotlanta! I have like 15 minute...\n",
       "3          1  Yay! Live improve musical theater is ridiculou...\n",
       "4          1  Weirdest night I have had in a long time! Haha..."
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gt9GPz0NhWim"
   },
   "outputs": [],
   "source": [
    "# Data clensing\n",
    "def cleantext(text):\n",
    "\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r'@[A-za-z0-9]+','',text) # remove @mentions\n",
    "    text = re.sub(r'RT[\\s]+','',text) #remove retweet\n",
    "    text = re.sub(r'https?:\\/\\/\\S+','',text) #remove hyperlink\n",
    "    text = re.sub(r'#','',text) #remove #\n",
    "\n",
    "    text = text.replace('\\n',' ')\n",
    "\n",
    "    text = contractions.fix(text)\n",
    "\n",
    "    stemmer = SnowballStemmer(language='english')\n",
    "    text = stemmer.stem(text)\n",
    "    text = re.sub(\"[\\.\\,\\!\\?\\:\\;\\-\\=\\*\\\"\\'\\“\\(\\)\\_]\", \"\",text) # remove puntucation\n",
    "    text = re.sub(\"[0123456789]\", \"\", text) # remove number\n",
    "\n",
    "    text = text.replace('  ',' ')\n",
    "\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q-M6XAf9hWip"
   },
   "outputs": [],
   "source": [
    "newdf['tweet_text'] = newdf['tweet_text'].apply(cleantext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xr1En-0chWis",
    "outputId": "176ba895-a059-40fa-bd2b-8479026a8a3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    yay yes drive right to us you can park the ves...\n",
       "1    just come join me the one in gardens just come...\n",
       "2    just landed in hotlanta i have like minutes ti...\n",
       "3    yay live improve musical theater is ridiculous...\n",
       "4    weirdest night i have had in a long time haha ...\n",
       "5    except i am flying in from the city that now h...\n",
       "6                                  that is embarassing\n",
       "7    well i will have lemon and ranch for you not f...\n",
       "8    what is up knee still bothering you i am sorry...\n",
       "9                                 going to the gym yay\n",
       "Name: tweet_text, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf['tweet_text'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pET2A8phdw0"
   },
   "source": [
    "# Start building the model with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4hvxv74Fo0ac",
    "outputId": "21466c75-bac0-4e07-e572-200f99ab4b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D1hzu_F7hWiw"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dot, Embedding, Flatten, GlobalAveragePooling1D, Reshape\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vTcT1U1LhWiz",
    "outputId": "b6b9e0d7-905e-4d83-b0ec-d9ba42f482f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1120000\n",
      "480000\n"
     ]
    }
   ],
   "source": [
    "X = newdf['tweet_text'].apply(str)\n",
    "y = newdf['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=20)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2tyCDZE_hWi3"
   },
   "outputs": [],
   "source": [
    "#Tokenize and fit with training data\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CTWfaXFPhWi6",
    "outputId": "259bc685-4c59-49e4-9135-d282cff243cf",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322058"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len = len(set(tokenizer.word_index))+1\n",
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q4OLilpahWi9"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train = pad_sequences(tokenizer.texts_to_sequences(X_train),maxlen = 200)\n",
    "X_test = pad_sequences(tokenizer.texts_to_sequences(X_test),maxlen = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_E1Vc2AChWjA"
   },
   "source": [
    "<h2>Load pre-trained word embeddings -  GloVe embeddings </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hdCwlOZUhWjB",
    "outputId": "0034ac17-03d5-4c7c-8db0-cc60d6f684fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-16 16:54:26--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2020-11-16 16:54:27--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2020-11-16 16:54:28--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  1.21MB/s    in 11m 5s  \n",
      "\n",
      "2020-11-16 17:05:34 (1.24 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZ79tfsShWjF"
   },
   "outputs": [],
   "source": [
    "path_to_glove_file = \"/content/drive/My Drive/Colab Notebooks/glove.6B.200d.txt\"\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "giefshEFhWjJ"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 200\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((vocab_len, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vPdkplLKhWjN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    vocab_len,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BdNWBUR0hWjR"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "638mwN_8hWjU",
    "outputId": "5a1a8019-632f-4840-b26b-c106fb34ee56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 200, 200)          64411600  \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 196, 128)          128128    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 39, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 35, 128)           82048     \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 64,737,233\n",
      "Trainable params: 325,633\n",
      "Non-trainable params: 64,411,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "int_sequences_input = layers.Input(shape=(200,), dtype='int32')\n",
    "embedding_sequences = embedding_layer(int_sequences_input)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(embedding_sequences)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(128, 5, activation='relu')(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64, dropout=0.2, recurrent_dropout=0.2))(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "preds = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = tf.keras.Model(int_sequences_input, preds)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "obpzfpWihWjX",
    "outputId": "35a39423-717e-42ff-f5c6-4a10395240fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8750/8750 [==============================] - 1256s 143ms/step - loss: 0.4957 - accuracy: 0.7583 - val_loss: 0.4716 - val_accuracy: 0.7734\n",
      "Epoch 2/20\n",
      "8750/8750 [==============================] - 1245s 142ms/step - loss: 0.4634 - accuracy: 0.7794 - val_loss: 0.4630 - val_accuracy: 0.7786\n",
      "Epoch 3/20\n",
      "8750/8750 [==============================] - 1246s 142ms/step - loss: 0.4494 - accuracy: 0.7878 - val_loss: 0.4625 - val_accuracy: 0.7797\n",
      "Epoch 4/20\n",
      "8750/8750 [==============================] - 1250s 143ms/step - loss: 0.4390 - accuracy: 0.7945 - val_loss: 0.4653 - val_accuracy: 0.7797\n",
      "Epoch 5/20\n",
      "8750/8750 [==============================] - 1264s 144ms/step - loss: 0.4304 - accuracy: 0.7991 - val_loss: 0.4640 - val_accuracy: 0.7800\n",
      "Epoch 6/20\n",
      "8750/8750 [==============================] - 1246s 142ms/step - loss: 0.4230 - accuracy: 0.8039 - val_loss: 0.4602 - val_accuracy: 0.7810\n",
      "Epoch 7/20\n",
      "8750/8750 [==============================] - 1248s 143ms/step - loss: 0.4165 - accuracy: 0.8078 - val_loss: 0.4683 - val_accuracy: 0.7800\n",
      "Epoch 8/20\n",
      "8750/8750 [==============================] - 1274s 146ms/step - loss: 0.4101 - accuracy: 0.8111 - val_loss: 0.4783 - val_accuracy: 0.7785\n",
      "Epoch 9/20\n",
      "8750/8750 [==============================] - 1274s 146ms/step - loss: 0.4052 - accuracy: 0.8140 - val_loss: 0.4776 - val_accuracy: 0.7788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9917dbd518>"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "my_callbacks = [tf.keras.callbacks.EarlyStopping(patience=3, monitor = 'val_loss'),]\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=20, validation_data=(X_test,y_test),callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ZrF3NM513IY",
    "outputId": "86c2b0de-2851-4c09-8fcf-84c8e4a57dfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/model/twitter_sentiment/assets\n"
     ]
    }
   ],
   "source": [
    "#save the model\n",
    "model.save(\"/content/drive/My Drive/Colab Notebooks/model/twitter_sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4rIqpHaqiRFn"
   },
   "outputs": [],
   "source": [
    "#pickle and save the tokenizer\n",
    "import pickle\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "twitter_model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
